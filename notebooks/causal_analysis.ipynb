{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Analysis for Cross-Modal Audience Intelligence\n",
    "\n",
    "This notebook demonstrates how to perform causal analysis on audience engagement data, including:\n",
    "- Causal structure discovery\n",
    "- Causal effect estimation\n",
    "- Counterfactual analysis\n",
    "- Causal feature selection\n",
    "- Actionable recommendations for optimizing content\n",
    "\n",
    "We'll use the structural causal model and counterfactual analysis tools from the CAIP platform to understand what truly drives audience engagement, going beyond simple correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (1.25.2)\n",
      "Requirement already satisfied: matplotlib in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: seaborn in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: networkx in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (3.4.2)\n",
      "Requirement already satisfied: scipy in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (1.15.1)\n",
      "Requirement already satisfied: tqdm in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: torch in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: pillow in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (10.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: filelock in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: requests in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->torchvision) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->torchvision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->torchvision) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->torchvision) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/gopalmacbook/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib seaborn networkx scipy tqdm torch torchvision scikit-learn pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Import CAIP causal inference components\n",
    "from causal.structural_model import CausalGraph, StructuralCausalModel\n",
    "from causal.causal_features import CausalFeatureSelector\n",
    "from causal.counterfactual import CounterfactualAnalyzer\n",
    "\n",
    "# Import other CAIP components as needed\n",
    "from models.text.text_features import TextFeatureExtractor\n",
    "from models.visual.visual_features import VisualFeatureExtractor\n",
    "from data.data_loader import DataLoader\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "Let's load our audience engagement dataset and prepare it for causal analysis. We'll use a combination of Nielsen panel data, streaming platform metrics, and content features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "DATA_DIR = \"./data\"\n",
    "MODELS_DIR = \"./models/saved\"\n",
    "RESULTS_DIR = \"./results/causal\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader(cache_dir=f\"{DATA_DIR}/cache\")\n",
    "\n",
    "try:\n",
    "    # Try to load processed data\n",
    "    audience_data = data_loader.load_processed_data()\n",
    "    print(f\"Loaded audience data with {len(audience_data)} entries\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No processed data found, creating synthetic data for demonstration\")\n",
    "    \n",
    "    # Generate synthetic data for demonstration\n",
    "    # This would be replaced with real data loading in production\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Create synthetic content features and engagement data\n",
    "    audience_data = pd.DataFrame({\n",
    "        'content_id': [f'SHOW{i:03d}' for i in range(n_samples)],\n",
    "        'content_duration': np.random.randint(15, 120, n_samples),  # in minutes\n",
    "        'episode_number': np.random.randint(1, 20, n_samples),\n",
    "        'genre_drama': np.random.randint(0, 2, n_samples),\n",
    "        'genre_comedy': np.random.randint(0, 2, n_samples),\n",
    "        'genre_action': np.random.randint(0, 2, n_samples),\n",
    "        'has_popular_actor': np.random.randint(0, 2, n_samples),\n",
    "        'budget_tier': np.random.randint(1, 4, n_samples),  # 1=low, 2=medium, 3=high\n",
    "        'promotion_level': np.random.randint(1, 5, n_samples),  # 1-4 scale\n",
    "        'title_length': np.random.randint(1, 8, n_samples),  # in words\n",
    "        'is_sequel': np.random.randint(0, 2, n_samples),\n",
    "        'thumbnail_brightness': np.random.uniform(0.2, 0.9, n_samples),\n",
    "        'thumbnail_saturation': np.random.uniform(0.3, 1.0, n_samples),\n",
    "        'content_freshness': np.random.randint(0, 100, n_samples),  # days since release\n",
    "        'description_sentiment': np.random.normal(0.2, 0.3, n_samples).clip(-1, 1),\n",
    "        'text_complexity': np.random.uniform(0.1, 0.9, n_samples),\n",
    "        'social_media_mentions': np.random.exponential(scale=50, size=n_samples).astype(int),\n",
    "        'weekday_release': np.random.randint(0, 2, n_samples),\n",
    "        'release_month': np.random.randint(1, 13, n_samples),\n",
    "        'similar_content_performance': np.random.normal(0.5, 0.15, n_samples).clip(0, 1)\n",
    "    })\n",
    "    \n",
    "    # Define the true causal structure for synthetic data generation\n",
    "    # This is our \"ground truth\" for demonstration purposes\n",
    "    \n",
    "    # Create engagement with a known causal structure\n",
    "    audience_data['engagement'] = (\n",
    "        0.3 * audience_data['promotion_level'] / 4 +\n",
    "        0.2 * audience_data['has_popular_actor'] +\n",
    "        0.15 * (audience_data['thumbnail_brightness'] > 0.6).astype(int) +\n",
    "        -0.1 * (audience_data['content_duration'] > 90).astype(int) +\n",
    "        0.2 * audience_data['genre_action'] -\n",
    "        0.15 * audience_data['content_freshness'] / 100 +\n",
    "        0.25 * audience_data['similar_content_performance'] +\n",
    "        0.1 * np.random.normal(0, 1, n_samples)  # Noise term\n",
    "    )\n",
    "    \n",
    "    # Normalize engagement to [0, 1] range\n",
    "    audience_data['engagement'] = (audience_data['engagement'] - audience_data['engagement'].min()) / \\\n",
    "                              (audience_data['engagement'].max() - audience_data['engagement'].min())\n",
    "    \n",
    "    print(f\"Created synthetic data with {len(audience_data)} samples\")\n",
    "\n",
    "# Display the first few rows\n",
    "audience_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Analysis\n",
    "\n",
    "Before diving into causal analysis, let's explore the correlations between features and engagement to see what traditional analysis would tell us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with engagement\n",
    "correlation_with_engagement = audience_data.corr()['engagement'].sort_values(ascending=False)\n",
    "\n",
    "# Plot correlation with engagement\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_with_engagement.drop('engagement').plot(kind='bar')\n",
    "plt.title('Correlation of Features with Engagement')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Pearson Correlation')\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display top correlations\n",
    "print(\"Top correlations with engagement:\")\n",
    "print(correlation_with_engagement.head(10))\n",
    "\n",
    "print(\"\\nBottom correlations with engagement:\")\n",
    "print(correlation_with_engagement.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between key features and engagement\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Select top correlated features\n",
    "top_features = correlation_with_engagement.drop('engagement').abs().sort_values(ascending=False).head(6).index\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    \n",
    "    # For categorical features, use box plot\n",
    "    if audience_data[feature].nunique() < 10:\n",
    "        sns.boxplot(x=feature, y='engagement', data=audience_data)\n",
    "        plt.title(f'{feature} vs Engagement')\n",
    "    # For continuous features, use scatter plot with regression line\n",
    "    else:\n",
    "        sns.regplot(x=feature, y='engagement', data=audience_data, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "        plt.title(f'{feature} vs Engagement (r={correlation_with_engagement[feature]:.2f})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Relationship Between Top Features and Engagement', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem with Correlation\n",
    "\n",
    "While correlation analysis gives us a starting point, it has critical limitations:\n",
    "\n",
    "1. **Spurious Correlations**: Features may correlate with engagement due to common causes, not direct effects\n",
    "2. **Confounding Variables**: Hidden factors can make non-causal features appear important\n",
    "3. **No Direction of Causality**: Correlation doesn't tell us if A causes B or vice versa\n",
    "4. **No Intervention Prediction**: Correlation can't reliably predict what will happen if we change a feature\n",
    "\n",
    "We need causal analysis to overcome these limitations and discover the true drivers of engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Causal Structure Discovery\n",
    "\n",
    "Let's discover the causal structure (graph) in our data to understand the relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for causal analysis (exclude IDs and other non-causal variables)\n",
    "causal_features = audience_data.drop(columns=['content_id', 'engagement']).columns.tolist()\n",
    "\n",
    "# Initialize structural causal model\n",
    "causal_model = StructuralCausalModel(\n",
    "    discovery_method='pc',  # Use PC algorithm for causal discovery\n",
    "    alpha=0.05,  # Significance level for independence tests\n",
    "    feature_names=causal_features\n",
    ")\n",
    "\n",
    "# Discover causal graph\n",
    "print(\"Discovering causal graph... This may take some time for complex data.\")\n",
    "start_time = time.time()\n",
    "\n",
    "causal_graph = causal_model.discover_graph(\n",
    "    data=audience_data[causal_features + ['engagement']],\n",
    "    outcome_var='engagement',\n",
    "    treatment_vars=['promotion_level', 'has_popular_actor', 'thumbnail_brightness',\n",
    "                   'genre_drama', 'genre_comedy', 'genre_action']\n",
    ")\n",
    "\n",
    "print(f\"Causal graph discovery completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Display some basic info about the graph\n",
    "print(f\"Number of nodes: {len(causal_graph.graph.nodes())}\")\n",
    "print(f\"Number of edges: {len(causal_graph.graph.edges())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the causal graph\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Create layout\n",
    "pos = nx.spring_layout(causal_graph.graph, seed=42, k=1.5)\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(\n",
    "    causal_graph.graph, pos,\n",
    "    with_labels=True,\n",
    "    node_color='lightblue',\n",
    "    node_size=3000,\n",
    "    font_size=10,\n",
    "    font_weight='bold',\n",
    "    edge_color='gray',\n",
    "    arrowsize=20,\n",
    "    arrowstyle='->',\n",
    "    width=1.5,\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "# Highlight the outcome node (engagement)\n",
    "nx.draw_networkx_nodes(\n",
    "    causal_graph.graph,\n",
    "    pos,\n",
    "    nodelist=['engagement'],\n",
    "    node_color='lightcoral',\n",
    "    node_size=3500\n",
    ")\n",
    "\n",
    "# Highlight direct causes of engagement\n",
    "direct_causes = list(causal_graph.get_parents('engagement'))\n",
    "if direct_causes:\n",
    "    nx.draw_networkx_nodes(\n",
    "        causal_graph.graph,\n",
    "        pos,\n",
    "        nodelist=direct_causes,\n",
    "        node_color='lightgreen',\n",
    "        node_size=3500\n",
    "    )\n",
    "    \n",
    "    # Highlight edges from direct causes to engagement\n",
    "    edges_to_engagement = [(cause, 'engagement') for cause in direct_causes]\n",
    "    nx.draw_networkx_edges(\n",
    "        causal_graph.graph,\n",
    "        pos,\n",
    "        edgelist=edges_to_engagement,\n",
    "        edge_color='green',\n",
    "        width=3,\n",
    "        arrowsize=25\n",
    "    )\n",
    "\n",
    "plt.title('Causal Graph of Audience Engagement Factors', fontsize=16)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='lightblue', markersize=15, label='Feature'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', markersize=15, label='Direct Cause of Engagement'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', markersize=15, label='Engagement (Outcome)'),\n",
    "    Line2D([0], [0], color='gray', lw=2, label='Causal Relationship'),\n",
    "    Line2D([0], [0], color='green', lw=2, label='Direct Effect on Engagement')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='lower right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/causal_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Causal Paths\n",
    "\n",
    "Let's analyze the causal paths to understand both direct and indirect effects on engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify direct causes of engagement\n",
    "direct_causes = list(causal_graph.get_parents('engagement'))\n",
    "print(f\"Direct causes of engagement: {direct_causes}\")\n",
    "\n",
    "# Find indirect causes (ancestors of engagement excluding direct causes)\n",
    "all_ancestors = causal_graph.get_ancestors('engagement')\n",
    "indirect_causes = [node for node in all_ancestors if node not in direct_causes]\n",
    "print(f\"Indirect causes of engagement: {indirect_causes}\")\n",
    "\n",
    "# Find confounders (variables that affect both a cause and the outcome)\n",
    "confounders = set()\n",
    "for cause in direct_causes:\n",
    "    cause_parents = set(causal_graph.get_parents(cause))\n",
    "    engagement_parents = set(direct_causes)\n",
    "    common_parents = cause_parents.intersection(engagement_parents)\n",
    "    confounders.update(common_parents)\n",
    "print(f\"Potential confounders: {confounders}\")\n",
    "\n",
    "# Calculate the minimal adjustment set for causal effect estimation\n",
    "for cause in direct_causes:\n",
    "    adjustment_set = causal_graph.get_minimal_adjustment_set(cause, 'engagement')\n",
    "    print(f\"Adjustment set for {cause} -> engagement: {adjustment_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Causal Effect Estimation\n",
    "\n",
    "Now that we've discovered the causal structure, let's estimate the causal effects to quantify how much each factor truly influences engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for estimating causal effects\n",
    "print(\"Fitting structural models...\")\n",
    "causal_model.fit_models(\n",
    "    data=audience_data[causal_features + ['engagement']],\n",
    "    model_type='random_forest',  # Use random forest for flexible modeling\n",
    "    outcome_vars=['engagement'] + direct_causes  # Model direct causes and outcome\n",
    ")\n",
    "\n",
    "# Estimate causal effects for all potential causal factors\n",
    "print(\"Estimating causal effects...\")\n",
    "causal_effects = causal_model.estimate_all_effects(\n",
    "    data=audience_data[causal_features + ['engagement']],\n",
    "    outcome='engagement',\n",
    "    method='backdoor',  # Use backdoor adjustment method\n",
    "    min_effect=0.01  # Minimum effect size to consider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert effects to DataFrame for easier analysis\n",
    "effects_df = pd.DataFrame([\n",
    "    {\n",
    "        'feature': feature,\n",
    "        'causal_effect': effect['causal_effect'],\n",
    "        'p_value': effect.get('p_value', float('nan')),\n",
    "        'significant': effect.get('p_value', 1.0) < 0.05,\n",
    "        'relative_effect': effect.get('relative_effect', float('nan'))\n",
    "    }\n",
    "    for feature, effect in causal_effects.items()\n",
    "])\n",
    "\n",
    "# Sort by absolute causal effect\n",
    "effects_df['abs_effect'] = effects_df['causal_effect'].abs()\n",
    "effects_df = effects_df.sort_values('abs_effect', ascending=False).drop('abs_effect', axis=1)\n",
    "\n",
    "# Display causal effects\n",
    "effects_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize causal effects\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot bars with confidence intervals\n",
    "effects = effects_df['causal_effect'].values\n",
    "features = effects_df['feature'].values\n",
    "significant = effects_df['significant'].values\n",
    "\n",
    "# Use different colors for significant vs non-significant effects\n",
    "colors = ['green' if sig else 'gray' for sig in significant]\n",
    "alphas = [0.8 if sig else 0.5 for sig in significant]\n",
    "\n",
    "y_pos = np.arange(len(features))\n",
    "bars = plt.barh(y_pos, effects, color=colors, alpha=alphas)\n",
    "\n",
    "# Add feature names\n",
    "plt.yticks(y_pos, features)\n",
    "plt.xlabel('Causal Effect on Engagement')\n",
    "plt.title('Estimated Causal Effects on Audience Engagement')\n",
    "\n",
    "# Add a vertical line at zero\n",
    "plt.axvline(x=0, color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='green', alpha=0.8, label='Significant (p < 0.05)'),\n",
    "    Patch(facecolor='gray', alpha=0.5, label='Not Significant')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/causal_effects.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation vs. Causation\n",
    "\n",
    "Now let's compare the correlation analysis with our causal analysis to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'feature': effects_df['feature'],\n",
    "    'causal_effect': effects_df['causal_effect'],\n",
    "    'correlation': [correlation_with_engagement.get(feature, 0) \n",
    "                   for feature in effects_df['feature']]\n",
    "})\n",
    "\n",
    "# Calculate the difference\n",
    "comparison_df['difference'] = comparison_df['causal_effect'] - comparison_df['correlation']\n",
    "comparison_df['abs_difference'] = comparison_df['difference'].abs()\n",
    "\n",
    "# Sort by absolute difference to highlight the most misleading correlations\n",
    "comparison_df = comparison_df.sort_values('abs_difference', ascending=False)\n",
    "\n",
    "# Display comparison\n",
    "comparison_df[['feature', 'causal_effect', 'correlation', 'difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Select top differences for clarity\n",
    "top_diff = comparison_df.head(12)\n",
    "\n",
    "# Set up bar positions\n",
    "bar_width = 0.35\n",
    "r1 = np.arange(len(top_diff))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create bars\n",
    "plt.barh(r1, top_diff['causal_effect'], bar_width, label='Causal Effect', color='green', alpha=0.7)\n",
    "plt.barh(r2, top_diff['correlation'], bar_width, label='Correlation', color='blue', alpha=0.7)\n",
    "\n",
    "# Add feature names\n",
    "plt.yticks([r + bar_width/2 for r in r1], top_diff['feature'])\n",
    "\n",
    "# Add a vertical line at zero\n",
    "plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Effect on Engagement')\n",
    "plt.title('Causal Effect vs. Correlation: Top Differences')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/causal_vs_correlation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Counterfactual Analysis\n",
    "\n",
    "Now let's perform counterfactual analysis to understand how interventions on specific features would affect engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counterfactual analyzer\n",
    "cf_analyzer = CounterfactualAnalyzer(causal_model)\n",
    "\n",
    "# Select a sample instance for counterfactual analysis\n",
    "# Choose an instance with moderate engagement\n",
    "engagement_median = audience_data['engagement'].median()\n",
    "sample_instance = audience_data[\n",
    "    (audience_data['engagement'] > engagement_median - 0.05) &\n",
    "    (audience_data['engagement'] < engagement_median + 0.05)\n",
    "].iloc[0]\n",
    "\n",
    "print(\"Sample instance for counterfactual analysis:\")\n",
    "for col in ['content_id', 'engagement'] + [col for col in effects_df['feature'][:8]]:\n",
    "    print(f\"{col}: {sample_instance[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals for top causal features\n",
    "top_causal_features = effects_df[effects_df['significant']]['feature'].head(5).tolist()\n",
    "counterfactuals = {}\n",
    "\n",
    "print(\"Generating counterfactuals for top causal features...\")\n",
    "for feature in top_causal_features:\n",
    "    # For binary features\n",
    "    if audience_data[feature].nunique() <= 2:\n",
    "        # Flip the value (0 to 1 or 1 to 0)\n",
    "        new_value = 1 - sample_instance[feature]\n",
    "        intervention = {feature: new_value}\n",
    "        \n",
    "    # For continuous features\n",
    "    else:\n",
    "        # Increase by 50%\n",
    "        current_value = sample_instance[feature]\n",
    "        new_value = current_value * 1.5\n",
    "        # Ensure we don't exceed the range of the data\n",
    "        new_value = min(new_value, audience_data[feature].max())\n",
    "        intervention = {feature: new_value}\n",
    "    \n",
    "    # Generate counterfactual\n",
    "    result = cf_analyzer.generate_counterfactual(\n",
    "        data=audience_data[causal_features + ['engagement']],\n",
    "        interventions=intervention,\n",
    "        outcome_var='engagement',\n",
    "        reference_values=sample_instance.to_dict()\n",
    "    )\n",
    "    \n",
    "    counterfactuals[feature] = result\n",
    "    \n",
    "    print(f\"\\nCounterfactual for {feature}:\")\n",
    "    print(f\"  Current value: {sample_instance[feature]}\")\n",
    "    print(f\"  Intervention: {intervention[feature]}\")\n",
    "    print(f\"  Factual engagement: {result['factual_outcome']:.4f}\")\n",
    "    print(f\"  Counterfactual engagement: {result['counterfactual_outcome']:.4f}\")\n",
    "    print(f\"  Change: {result['outcome_change']:.4f} ({result['outcome_change_percent']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize counterfactual results\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Extract data for plotting\n",
    "features = list(counterfactuals.keys())\n",
    "factual = [cf['factual_outcome'] for cf in counterfactuals.values()]\n",
    "counterfactual = [cf['counterfactual_outcome'] for cf in counterfactuals.values()]\n",
    "changes = [cf['outcome_change'] for cf in counterfactuals.values()]\n",
    "\n",
    "# Calculate positions\n",
    "x = np.arange(len(features))\n",
    "width = 0.35\n",
    "\n",
    "# Create grouped bar chart\n",
    "plt.bar(x - width/2, factual, width, label='Factual Engagement', color='blue', alpha=0.7)\n",
    "plt.bar(x + width/2, counterfactual, width, label='Counterfactual Engagement', color='green', alpha=0.7)\n",
    "\n",
    "# Add feature names\n",
    "plt.xticks(x, features)\n",
    "plt.xlabel('Intervened Feature')\n",
    "plt.ylabel('Engagement Score')\n",
    "plt.title('Counterfactual Analysis of Feature Interventions')\n",
    "plt.legend()\n",
    "\n",
    "# Add percentage change annotations\n",
    "for i, change in enumerate(changes):\n",
    "    pct_change = change / factual[i] * 100 if factual[i] != 0 else float('inf')\n",
    "    plt.annotate(\n",
    "        f'{pct_change:+.1f}%',\n",
    "        xy=(x[i], max(factual[i], counterfactual[i]) + 0.02),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontweight='bold',\n",
    "        color='black' if pct_change > 0 else 'red'\n",
    "    )\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/counterfactual_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Finding Optimal Interventions\n",
    "\n",
    "Let's find the optimal interventions to maximize engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal interventions to maximize engagement\n",
    "print(\"Finding optimal interventions to maximize engagement...\")\n",
    "optimal_result = cf_analyzer.find_optimal_intervention(\n",
    "    data=audience_data[causal_features + ['engagement']],\n",
    "    outcome_var='engagement',\n",
    "    target_outcome=0.9,  # Target high engagement\n",
    "    candidate_features=effects_df[effects_df['significant']]['feature'].tolist(),\n",
    "    reference_values=sample_instance.to_dict(),\n",
    "    max_features=3  # Limit to 3 features for simplicity\n",
    ")\n",
    "\n",
    "print(\"\\nOptimal intervention strategy:\")\n",
    "print(f\"Baseline engagement: {optimal_result['baseline_outcome']:.4f}\")\n",
    "print(f\"Predicted engagement after intervention: {optimal_result['predicted_outcome']:.4f}\")\n",
    "print(f\"Improvement: {optimal_result['improvement']:.4f} ({optimal_result['percent_improvement']:.2f}%)\")\n",
    "print(\"\\nFeature interventions:\")\n",
    "for feature, value in optimal_result['optimal_intervention'].items():\n",
    "    original_value = sample_instance[feature]\n",
    "    print(f\"  {feature}: {original_value:.4f} -> {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis for key features\n",
    "print(\"Performing sensitivity analysis...\")\n",
    "feature_to_analyze = effects_df['feature'].iloc[0]  # Top causal feature\n",
    "\n",
    "sensitivity = cf_analyzer.analyze_sensitivity(\n",
    "    data=audience_data[causal_features + ['engagement']],\n",
    "    outcome_var='engagement',\n",
    "    feature=feature_to_analyze,\n",
    "    reference_values=sample_instance.to_dict(),\n",
    "    perturbation_range=0.3,  # Perturb by ±30%\n",
    "    num_points=15\n",
    ")\n",
    "\n",
    "print(f\"\\nSensitivity analysis for {feature_to_analyze}:\")\n",
    "print(f\"Reference value: {sensitivity['reference_value']:.4f}\")\n",
    "print(f\"Average elasticity: {sensitivity['average_elasticity']:.4f}\")\n",
    "print(f\"Sensitivity score: {sensitivity['sensitivity_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensitivity analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot outcomes vs perturbation values\n",
    "plt.plot(\n",
    "    sensitivity['perturbation_values'],\n",
    "    sensitivity['outcomes'],\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    linewidth=2,\n",
    "    markersize=8\n",
    ")\n",
    "\n",
    "# Highlight reference point\n",
    "ref_idx = np.abs(np.array(sensitivity['perturbation_values']) - sensitivity['reference_value']).argmin()\n",
    "plt.plot(\n",
    "    sensitivity['perturbation_values'][ref_idx],\n",
    "    sensitivity['outcomes'][ref_idx],\n",
    "    marker='o',\n",
    "    markersize=12,\n",
    "    markerfacecolor='red',\n",
    "    markeredgecolor='black',\n",
    "    markeredgewidth=2,\n",
    "    label='Reference Point'\n",
    ")\n",
    "\n",
    "plt.xlabel(f\"{feature_to_analyze} Value\")\n",
    "plt.ylabel('Engagement')\n",
    "plt.title(f'Sensitivity of Engagement to Changes in {feature_to_analyze}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add elasticity info\n",
    "plt.annotate(\n",
    "    f\"Elasticity: {sensitivity['average_elasticity']:.2f}\\nSensitivity: {sensitivity['sensitivity_score']:.2f}\",\n",
    "    xy=(0.05, 0.95),\n",
    "    xycoords='axes fraction',\n",
    "    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/sensitivity_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Causal Feature Selection\n",
    "\n",
    "Let's use causal feature selection to identify the most important causal features for audience engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize causal feature selector\n",
    "feature_selector = CausalFeatureSelector(causal_model)\n",
    "\n",
    "# Fit the selector to identify causal features\n",
    "causal_features_dict = feature_selector.fit(\n",
    "    data=audience_data[causal_features + ['engagement']],\n",
    "    outcome_var='engagement',\n",
    "    discovery_method='manual',  # Use the already discovered graph\n",
    "    exclude_vars=[]\n",
    ")\n",
    "\n",
    "# Get top causal features\n",
    "top_features = feature_selector.get_top_features(n=10)\n",
    "print(\"Top causal features:\")\n",
    "for feature, effect in top_features.items():\n",
    "    print(f\"  {feature}: {effect:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize causal features\n",
    "feature_selector.visualize_causal_features(\n",
    "    figsize=(16, 10),\n",
    "    show_effect_size=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a feature importance summary\n",
    "feature_summary = feature_selector.feature_effect_summary()\n",
    "feature_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Actionable Recommendations\n",
    "\n",
    "Based on our causal analysis, let's generate actionable recommendations to optimize content for audience engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations for a specific piece of content\n",
    "sample_content = audience_data.iloc[10]  # Select a sample content item\n",
    "target_engagement = 0.8  # Set a high target engagement\n",
    "\n",
    "print(f\"Content ID: {sample_content['content_id']}\")\n",
    "print(f\"Current engagement: {sample_content['engagement']:.4f}\")\n",
    "print(f\"Target engagement: {target_engagement:.4f}\")\n",
    "\n",
    "# Set feature constraints based on what can realistically be changed\n",
    "constraints = {\n",
    "    # Some features can't be changed or have limited range\n",
    "    'content_duration': (sample_content['content_duration'] * 0.9, sample_content['content_duration'] * 1.1),  # ±10%\n",
    "    'genre_drama': (0, 1),  # Binary constraint\n",
    "    'genre_comedy': (0, 1),  # Binary constraint\n",
    "    'genre_action': (0, 1),  # Binary constraint\n",
    "    'has_popular_actor': (sample_content['has_popular_actor'], 1),  # Can only add, not remove actors\n",
    "    'promotion_level': (sample_content['promotion_level'], 4),  # Can only increase up to max (4)\n",
    "    'thumbnail_brightness': (0.2, 0.9),\n",
    "    'thumbnail_saturation': (0.3, 1.0)\n",
    "}\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = feature_selector.generate_feature_recommendations(\n",
    "    target_outcome=target_engagement,\n",
    "    current_values=sample_content.to_dict(),\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# Display recommendations\n",
    "print(\"\\nRecommended changes to achieve target engagement:\")\n",
    "for feature, rec in recommendations.items():\n",
    "    print(f\"  {feature}: {rec['current_value']:.4f} -> {rec['recommended_value']:.4f} (Impact: {rec['impact']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recommendations\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Extract data for plotting\n",
    "features = list(recommendations.keys())\n",
    "current = [rec['current_value'] for rec in recommendations.values()]\n",
    "recommended = [rec['recommended_value'] for rec in recommendations.values()]\n",
    "impacts = [rec['impact'] for rec in recommendations.values()]\n",
    "\n",
    "# Sort by absolute impact\n",
    "impact_abs = [abs(impact) for impact in impacts]\n",
    "sorted_indices = np.argsort(impact_abs)[::-1]\n",
    "\n",
    "features = [features[i] for i in sorted_indices]\n",
    "current = [current[i] for i in sorted_indices]\n",
    "recommended = [recommended[i] for i in sorted_indices]\n",
    "impacts = [impacts[i] for i in sorted_indices]\n",
    "\n",
    "# Get top 5 recommendations by impact\n",
    "features = features[:5]\n",
    "current = current[:5]\n",
    "recommended = recommended[:5]\n",
    "impacts = impacts[:5]\n",
    "\n",
    "# Normalize values for better visualization\n",
    "max_values = [max(curr, rec) for curr, rec in zip(current, recommended)]\n",
    "current_norm = [curr / max_val if max_val != 0 else 0 for curr, max_val in zip(current, max_values)]\n",
    "recommended_norm = [rec / max_val if max_val != 0 else 0 for rec, max_val in zip(recommended, max_values)]\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(features))\n",
    "width = 0.35\n",
    "\n",
    "# Create bars\n",
    "plt.bar(x - width/2, current_norm, width, label='Current Value', color='blue', alpha=0.7)\n",
    "plt.bar(x + width/2, recommended_norm, width, label='Recommended Value', color='green', alpha=0.7)\n",
    "\n",
    "# Add feature names\n",
    "plt.xticks(x, features, rotation=45, ha='right')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Relative Value')\n",
    "plt.title('Top Feature Recommendations for Optimal Engagement')\n",
    "plt.legend()\n",
    "\n",
    "# Add impact annotations\n",
    "for i, impact in enumerate(impacts):\n",
    "    plt.annotate(\n",
    "        f'Impact: {impact:.3f}',\n",
    "        xy=(x[i], max(current_norm[i], recommended_norm[i]) + 0.05),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontweight='bold',\n",
    "        color='darkgreen' if impact > 0 else 'darkred'\n",
    "    )\n",
    "\n",
    "plt.ylim(0, 1.3)  # Set y-axis limit with room for annotations\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/feature_recommendations.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Causal Model for Production Use\n",
    "\n",
    "Let's save the causal model for use in production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the causal model\n",
    "model_path = f\"{MODELS_DIR}/causal_model.pt\"\n",
    "causal_model.save(model_path)\n",
    "print(f\"Saved causal model to {model_path}\")\n",
    "\n",
    "# Test loading the model\n",
    "loaded_model = StructuralCausalModel.load(model_path)\n",
    "print(\"Successfully loaded causal model\")\n",
    "\n",
    "# Save key insights and findings\n",
    "insights = {\n",
    "    \"causal_effects\": {feature: float(effect) for feature, effect in causal_features_dict.items()},\n",
    "    \"top_features\": {feature: float(effect) for feature, effect in top_features.items()},\n",
    "    \"direct_causes\": direct_causes,\n",
    "    \"indirect_causes\": indirect_causes,\n",
    "    \"confounders\": list(confounders),\n",
    "    \"sample_recommendations\": {\n",
    "        feature: {\n",
    "            \"current\": float(rec[\"current_value\"]),\n",
    "            \"recommended\": float(rec[\"recommended_value\"]),\n",
    "            \"impact\": float(rec[\"impact\"])\n",
    "        } for feature, rec in recommendations.items()\n",
    "    },\n",
    "    \"analysis_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "# Save insights to JSON\n",
    "insights_path = f\"{RESULTS_DIR}/causal_insights.json\"\n",
    "with open(insights_path, 'w') as f:\n",
    "    json.dump(insights, f, indent=2)\n",
    "print(f\"Saved causal insights to {insights_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how causal analysis goes beyond traditional correlational analysis to uncover the true drivers of audience engagement.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Causal Structure**: We discovered the causal relationships between content features and audience engagement\n",
    "2. **Causal Effects**: We quantified the true causal impact of each feature on engagement\n",
    "3. **Correlation vs. Causation**: We identified features that were misleadingly correlated but not causal\n",
    "4. **Counterfactual Analysis**: We predicted how changing features would affect engagement\n",
    "5. **Optimal Interventions**: We found the most effective changes to maximize engagement\n",
    "6. **Actionable Recommendations**: We generated specific recommendations for optimizing content\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Content Strategy**: Focus resources on modifying the most impactful features\n",
    "- **A/B Testing**: Design tests based on causal insights rather than correlations\n",
    "- **Audience Targeting**: Better understand which factors truly drive engagement for different audience segments\n",
    "- **Content Optimization**: Automatically recommend changes to improve engagement\n",
    "- **ROI Analysis**: Prioritize investments based on causal impact rather than misleading correlations\n",
    "\n",
    "By applying causal inference to audience intelligence, we can make more informed decisions and create more engaging content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
